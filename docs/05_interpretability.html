<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.189">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>12 Deep Lift</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="05_interpretability_files/libs/clipboard/clipboard.min.js"></script>
<script src="05_interpretability_files/libs/quarto-html/quarto.js"></script>
<script src="05_interpretability_files/libs/quarto-html/popper.min.js"></script>
<script src="05_interpretability_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="05_interpretability_files/libs/quarto-html/anchor.min.js"></script>
<link href="05_interpretability_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="05_interpretability_files/libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="05_interpretability_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="05_interpretability_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="05_interpretability_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="dark">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#data" id="toc-data" class="nav-link active" data-scroll-target="#data"><span class="toc-section-number">1</span>  Data</a></li>
  <li><a href="#deeplift" id="toc-deeplift" class="nav-link" data-scroll-target="#deeplift"><span class="toc-section-number">2</span>  DeepLift</a>
  <ul class="collapse">
  <li><a href="#klf4-e2-enhancer-supplementary-fig.2" id="toc-klf4-e2-enhancer-supplementary-fig.2" class="nav-link" data-scroll-target="#klf4-e2-enhancer-supplementary-fig.2"><span class="toc-section-number">2.0.1</span>  Klf4 E2 enhancer (Supplementary Fig.2)</a></li>
  <li><a href="#nanog-enhancer-supplementary-fig.2" id="toc-nanog-enhancer-supplementary-fig.2" class="nav-link" data-scroll-target="#nanog-enhancer-supplementary-fig.2"><span class="toc-section-number">2.0.2</span>  Nanog enhancer (Supplementary Fig.2)</a></li>
  <li><a href="#fbx15-enhancer-supplementary-fig.2" id="toc-fbx15-enhancer-supplementary-fig.2" class="nav-link" data-scroll-target="#fbx15-enhancer-supplementary-fig.2"><span class="toc-section-number">2.0.3</span>  Fbx15 enhancer (Supplementary Fig.2)</a></li>
  </ul></li>
  <li><a href="#input-x-gradient" id="toc-input-x-gradient" class="nav-link" data-scroll-target="#input-x-gradient"><span class="toc-section-number">3</span>  Input x Gradient</a>
  <ul class="collapse">
  <li><a href="#klf4-e2-enhancer-supplementary-fig.2-1" id="toc-klf4-e2-enhancer-supplementary-fig.2-1" class="nav-link" data-scroll-target="#klf4-e2-enhancer-supplementary-fig.2-1"><span class="toc-section-number">3.0.1</span>  Klf4 E2 enhancer (Supplementary Fig.2)</a></li>
  <li><a href="#nanog-enhancer-supplementary-fig.2-1" id="toc-nanog-enhancer-supplementary-fig.2-1" class="nav-link" data-scroll-target="#nanog-enhancer-supplementary-fig.2-1"><span class="toc-section-number">3.0.2</span>  Nanog enhancer (Supplementary Fig.2)</a></li>
  <li><a href="#fbx15-enhancer-supplementary-fig.2-1" id="toc-fbx15-enhancer-supplementary-fig.2-1" class="nav-link" data-scroll-target="#fbx15-enhancer-supplementary-fig.2-1"><span class="toc-section-number">3.0.3</span>  Fbx15 enhancer (Supplementary Fig.2)</a></li>
  </ul></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">12 Deep Lift</h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.style.use('dark_background')</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.architectures <span class="im">import</span> <span class="op">*</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.utils <span class="im">import</span> <span class="op">*</span> </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.loss <span class="im">import</span> <span class="op">*</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.metrics <span class="im">import</span> <span class="op">*</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> src.DeepLiftUtils <span class="im">import</span> <span class="op">*</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> captum.attr <span class="im">import</span> DeepLift</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> modisco.visualization</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> modisco.visualization <span class="im">import</span> viz_sequence</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Test</p>
<section id="data" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Data</h1>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>TF_LIST <span class="op">=</span> [<span class="st">"Nanog"</span>, <span class="st">"Klf4"</span>, <span class="st">"Oct4"</span>, <span class="st">"Sox2"</span>]</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>OUTPUT_DIR <span class="op">=</span> <span class="st">"/home/kathi/AML_Project/data/figures_new1/"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Using </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss"> device"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Using cuda device</code></pre>
</div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> ChIP_Nexus_Dataset(set_name<span class="op">=</span><span class="st">"train"</span>, </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>                                   input_dir<span class="op">=</span><span class="st">"/home/philipp/AML_Final_Project/output_6/"</span>, </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>                                   TF_list<span class="op">=</span>TF_LIST)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>train_dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>ChIP_Nexus_Dataset
Set: train
TFs: ['Nanog', 'Klf4', 'Oct4', 'Sox2']
Size: 93904</code></pre>
</div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>tune_dataset <span class="op">=</span> ChIP_Nexus_Dataset(set_name<span class="op">=</span><span class="st">"tune"</span>, </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>                                  input_dir<span class="op">=</span><span class="st">"/home/philipp/AML_Final_Project/output_6/"</span>, </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>                                  TF_list<span class="op">=</span>TF_LIST)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>tune_dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>ChIP_Nexus_Dataset
Set: tune
TFs: ['Nanog', 'Klf4', 'Oct4', 'Sox2']
Size: 29277</code></pre>
</div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> ChIP_Nexus_Dataset(set_name<span class="op">=</span><span class="st">"test"</span>, </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>                                  input_dir<span class="op">=</span><span class="st">"/home/philipp/AML_Final_Project/output_6/"</span>, </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>                                  TF_list<span class="op">=</span>TF_LIST)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>test_dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>ChIP_Nexus_Dataset
Set: test
TFs: ['Nanog', 'Klf4', 'Oct4', 'Sox2']
Size: 27727</code></pre>
</div>
</div>
<p>For interpretability methods like DeepLift (https://github.com/kundajelab/deeplift) , integrated gradients or gradient x input, we require a scalar output. The BPNet model does, however, predict profiles shapes as tensors of size 2 x 1000 (strand x bps). For backpropagation or DeepLift we collapse the profile for each strand to one representative value, which can then be used to compute the gradient of this scalar with respect to each of the input bps.</p>
<p>We define our profile prediction as the softmax of the pre-activation of the last layer in our profile shape prediction head.</p>
<p><span class="math inline">\(\tilde{z}\)</span> is the pre-activation of our last layer.</p>
<p><span class="math inline">\(p = softmax(\tilde{z}) = \frac{\exp{\tilde{z}}}{\sum_{i}^{N}{\exp{\tilde{z'}_i}}}\)</span> with <span class="math inline">\(N\)</span> corresponding to the number of bps.</p>
<p>We weight the pre-activations of the last layer with the softmax of the same pre-activations and take the sum. This way we get one value for each strand.</p>
<p><span class="math inline">\(z = \sum_{i}^{N}{p_i * \tilde{z}_i}\)</span> with <span class="math inline">\(z \in \mathbb{R}^{2}\)</span></p>
<p>Importantly, we have to detach the softmax activation so that it is a constant value during backpropagation of contribution scores or gradients.</p>
<p>When computing DeepLift scores we take the average of the two strands.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> torch.load(<span class="st">"../trained_models/all_tfs_model.pt"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="deeplift" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> DeepLift</h1>
<p>We picked some exemplary regions of interest from the paper (Fig.2 and Supp.Fig.2) to compute the contribution scores and make some plots.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>dl <span class="op">=</span> DeepLift(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_contr_region(seqname, start, end, dataset, model, dl, device, tf_list, output_dir, plot<span class="op">=</span><span class="va">True</span>, figsize1<span class="op">=</span>(<span class="dv">20</span>,<span class="dv">2</span>), figsize2<span class="op">=</span>(<span class="dv">10</span>,<span class="fl">1.5</span>)):</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Compute the DeepLift contribution scores for a 1kb sequence which contains the shorter </span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co">    region of interest specified by the input arguments.</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Params:</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co">        seq_name: string</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co">            specifies the chromosome </span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co">        start: int</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co">            specifies start coordinate of sequence of interest on chromosome</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co">        end: int</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co">            specifies end coordinate of sequence of interest on chromsome</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co">        dataset: utils.ChIP_Nexus_Dataset object</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co">        device: cuda or cpu</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="co">        tf_list: </span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="co">            Contains names of TFs for which we want to compute the contributions</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="co">        plot: bool</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="co">            Whether to visualize the DeepLift contribution scores.</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a><span class="co">        contr: tensor (4x1000)</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a><span class="co">            Contains the contribution of each bp to the profile shape predictions for the input sequence.</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a><span class="co">        dist_start: int</span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="co">            distance between the start of the 1kb sequence and the region of interest</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># select sequence of interest</span></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>    tmp_df, idx, dist_start, one_hot, baseline, bias_raw, bias_smooth, tf_counts <span class="op">=</span> get_seq_oi(seqname, start, end, dataset, device)</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>    width <span class="op">=</span> end <span class="op">-</span> start</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute contribution scores for each tf</span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>    contr_list <span class="op">=</span> []</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>    plot_df <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">"pos"</span>, <span class="st">"TF"</span>, <span class="st">"pos_values"</span>, <span class="st">"neg_values"</span>])</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> tf_index, tf <span class="kw">in</span> <span class="bu">enumerate</span>(tf_list):</span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>        contr <span class="op">=</span> dl.attribute(inputs<span class="op">=</span>one_hot, baselines<span class="op">=</span>baseline, target<span class="op">=</span>(tf_index), additional_forward_args<span class="op">=</span>(bias_raw, bias_smooth, <span class="va">True</span>)).detach().cpu().numpy()</span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>        contr_list.append(contr)</span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>        pred, _ <span class="op">=</span> model.forward(one_hot, bias_raw, bias_smooth, interpretation<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> pred.detach().cpu().numpy().squeeze()</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># scale prediciton with total counts</span></span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> pred <span class="op">*</span> tf_counts.<span class="bu">sum</span>(axis<span class="op">=-</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>        tf_df <span class="op">=</span> pd.DataFrame({<span class="st">"pos"</span>: np.arange(width<span class="op">+</span><span class="dv">1</span>), <span class="st">"TF"</span>: tf, <span class="st">"pos_values"</span>: pred[tf_index, <span class="dv">0</span>, dist_start : (dist_start <span class="op">+</span> width<span class="op">+</span><span class="dv">1</span>)], <span class="st">"neg_values"</span>: pred[tf_index, <span class="dv">1</span>, dist_start : (dist_start <span class="op">+</span> width<span class="op">+</span><span class="dv">1</span>)]})</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>        plot_df <span class="op">=</span> plot_df.append(tf_df)</span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> plot:</span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>            <span class="co"># entire sequence original</span></span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>            plot_weights(contr,</span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>            fontsizes<span class="op">=</span>[<span class="dv">20</span>,<span class="dv">15</span>,<span class="dv">15</span>],</span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a>            title <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>tf<span class="sc">}</span><span class="ss"> - 1kbp sequence"</span>, </span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>            xlabel<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>tmp_df<span class="sc">.</span>seqnames[idx]<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>tmp_df<span class="sc">.</span>start[idx]<span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>tmp_df<span class="sc">.</span>end[idx]<span class="sc">}</span><span class="ss">"</span>, </span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>            ylabel<span class="op">=</span><span class="st">"DeepLift contribution scores"</span>,</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>            subticks_frequency<span class="op">=</span><span class="dv">20</span>, figsize<span class="op">=</span>figsize1)</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a>            plt.savefig(<span class="ss">f"</span><span class="sc">{</span>output_dir<span class="sc">}{</span>tf<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>seqname<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>start<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>end<span class="sc">}</span><span class="ss">_entireSeq_DeepLift.pdf"</span>)</span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>            <span class="co"># zoomed into motif region</span></span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a>            plot_weights(contr[:, :,dist_start : (dist_start <span class="op">+</span> width<span class="op">+</span><span class="dv">1</span>)],</span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a>            fontsizes<span class="op">=</span>[<span class="dv">20</span>,<span class="dv">15</span>,<span class="dv">15</span>],</span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a>            title <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>tf<span class="sc">}</span><span class="ss"> - Motif of interest"</span>, </span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a>            xlabel<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>seqname<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>start<span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>end<span class="sc">}</span><span class="ss">, (</span><span class="sc">{</span>dist_start<span class="sc">}</span><span class="ss"> - </span><span class="sc">{</span>dist_start <span class="op">+</span> width<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">)"</span>, </span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a>            ylabel<span class="op">=</span><span class="st">"DeepLift contribution scores"</span>,</span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a>            subticks_frequency<span class="op">=</span><span class="dv">10</span>, figsize<span class="op">=</span>figsize2)</span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a>            plt.savefig(<span class="ss">f"</span><span class="sc">{</span>output_dir<span class="sc">}{</span>tf<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>seqname<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>start<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>end<span class="sc">}</span><span class="ss">_zoomedSeq_DeepLift.pdf"</span>)  </span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a>            <span class="co"># plot profiles</span></span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a>            fig, axis <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>,figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">4</span>))</span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a>            axis[<span class="dv">0</span>].plot(tf_counts[tf_index, <span class="dv">0</span>, :], label<span class="op">=</span><span class="st">"true counts"</span>, color<span class="op">=</span><span class="st">"green"</span>, linewidth<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a>            axis[<span class="dv">0</span>].plot(<span class="op">-</span>tf_counts[tf_index, <span class="dv">1</span>, :], color<span class="op">=</span><span class="st">"green"</span>, linewidth<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a>            axis[<span class="dv">0</span>].plot(pred[tf_index, <span class="dv">0</span>, :], label<span class="op">=</span><span class="st">"pred"</span>, color<span class="op">=</span><span class="st">"blue"</span>, linewidth<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a>            axis[<span class="dv">0</span>].plot(<span class="op">-</span>pred[tf_index, <span class="dv">1</span>, :], color<span class="op">=</span><span class="st">"blue"</span>, linewidth<span class="op">=</span><span class="fl">0.8</span>)   </span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a>            axis[<span class="dv">0</span>].set_xlabel(<span class="st">"bp"</span>)</span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a>            axis[<span class="dv">0</span>].set_ylabel(<span class="st">"Read counts"</span>)</span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a>            axis[<span class="dv">1</span>].plot(pred[tf_index, <span class="dv">0</span>, :], label<span class="op">=</span><span class="st">"pred"</span>, color<span class="op">=</span><span class="st">"blue"</span>, linewidth<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a>            axis[<span class="dv">1</span>].plot(<span class="op">-</span>pred[tf_index, <span class="dv">1</span>, :], color<span class="op">=</span><span class="st">"blue"</span>, linewidth<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a>            axis[<span class="dv">1</span>].set_xlabel(<span class="st">"bp"</span>)</span>
<span id="cb13-73"><a href="#cb13-73" aria-hidden="true" tabindex="-1"></a>            axis[<span class="dv">1</span>].set_ylabel(<span class="st">"Predicted probabilitiy * total counts"</span>)</span>
<span id="cb13-74"><a href="#cb13-74" aria-hidden="true" tabindex="-1"></a>            axis[<span class="dv">0</span>].legend()</span>
<span id="cb13-75"><a href="#cb13-75" aria-hidden="true" tabindex="-1"></a>            axis[<span class="dv">1</span>].legend()</span>
<span id="cb13-76"><a href="#cb13-76" aria-hidden="true" tabindex="-1"></a>            plt.show()</span>
<span id="cb13-77"><a href="#cb13-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-78"><a href="#cb13-78" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb13-79"><a href="#cb13-79" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> contr, dist_start, plot_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="klf4-e2-enhancer-supplementary-fig.2" class="level3" data-number="2.0.1">
<h3 data-number="2.0.1" class="anchored" data-anchor-id="klf4-e2-enhancer-supplementary-fig.2"><span class="header-section-number">2.0.1</span> Klf4 E2 enhancer (Supplementary Fig.2)</h3>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>contr, dist_start, pred <span class="op">=</span> get_contr_region(<span class="st">"chr4"</span>, start<span class="op">=</span><span class="dv">55475545</span>, end<span class="op">=</span><span class="dv">55475604</span>, dataset<span class="op">=</span>tune_dataset, output_dir<span class="op">=</span>OUTPUT_DIR, dl<span class="op">=</span>dl, tf_list<span class="op">=</span>TF_LIST, device<span class="op">=</span>device, model<span class="op">=</span>model)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co">#pred.to_csv("/home/kathi/AML_Project/data/test_fig.csv")</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kathi/miniconda3/envs/final_project_aml/lib/python3.10/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.
  warnings.warn(
/home/kathi/miniconda3/envs/final_project_aml/lib/python3.10/site-packages/captum/attr/_core/deep_lift.py:336: UserWarning: Setting forward, backward hooks and attributes on non-linear
               activations. The hooks and attributes will be removed
            after the attribution is finished
  warnings.warn(
/tmp/ipykernel_427167/809386396.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  plot_df = plot_df.append(tf_df)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-11-output-2.png" width="1590" height="302"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-11-output-3.png" width="830" height="302"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-11-output-4.png" width="968" height="350"></p>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kathi/miniconda3/envs/final_project_aml/lib/python3.10/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.
  warnings.warn(
/home/kathi/miniconda3/envs/final_project_aml/lib/python3.10/site-packages/captum/attr/_core/deep_lift.py:336: UserWarning: Setting forward, backward hooks and attributes on non-linear
               activations. The hooks and attributes will be removed
            after the attribution is finished
  warnings.warn(
/tmp/ipykernel_427167/809386396.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  plot_df = plot_df.append(tf_df)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-11-output-6.png" width="1598" height="302"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-11-output-7.png" width="839" height="302"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-11-output-8.png" width="968" height="350"></p>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kathi/miniconda3/envs/final_project_aml/lib/python3.10/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.
  warnings.warn(
/home/kathi/miniconda3/envs/final_project_aml/lib/python3.10/site-packages/captum/attr/_core/deep_lift.py:336: UserWarning: Setting forward, backward hooks and attributes on non-linear
               activations. The hooks and attributes will be removed
            after the attribution is finished
  warnings.warn(
/tmp/ipykernel_427167/809386396.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  plot_df = plot_df.append(tf_df)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-11-output-10.png" width="1590" height="302"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-11-output-11.png" width="830" height="302"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-11-output-12.png" width="972" height="350"></p>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kathi/miniconda3/envs/final_project_aml/lib/python3.10/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.
  warnings.warn(
/home/kathi/miniconda3/envs/final_project_aml/lib/python3.10/site-packages/captum/attr/_core/deep_lift.py:336: UserWarning: Setting forward, backward hooks and attributes on non-linear
               activations. The hooks and attributes will be removed
            after the attribution is finished
  warnings.warn(
/tmp/ipykernel_427167/809386396.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  plot_df = plot_df.append(tf_df)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-11-output-14.png" width="1590" height="302"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-11-output-15.png" width="830" height="302"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-11-output-16.png" width="968" height="350"></p>
</div>
</div>
</section>
<section id="nanog-enhancer-supplementary-fig.2" class="level3" data-number="2.0.2">
<h3 data-number="2.0.2" class="anchored" data-anchor-id="nanog-enhancer-supplementary-fig.2"><span class="header-section-number">2.0.2</span> Nanog enhancer (Supplementary Fig.2)</h3>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>contr, dist_start, pred <span class="op">=</span> get_contr_region(<span class="st">"chr6"</span>, start<span class="op">=</span><span class="dv">122707394</span>, end<span class="op">=</span><span class="dv">122707454</span>, dataset<span class="op">=</span>train_dataset, output_dir<span class="op">=</span>OUTPUT_DIR, dl<span class="op">=</span>dl, tf_list<span class="op">=</span>TF_LIST, device<span class="op">=</span>device, model<span class="op">=</span>model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kathi/miniconda3/envs/final_project_aml/lib/python3.10/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.
  warnings.warn(
/home/kathi/miniconda3/envs/final_project_aml/lib/python3.10/site-packages/captum/attr/_core/deep_lift.py:336: UserWarning: Setting forward, backward hooks and attributes on non-linear
               activations. The hooks and attributes will be removed
            after the attribution is finished
  warnings.warn(
/tmp/ipykernel_427167/809386396.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  plot_df = plot_df.append(tf_df)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-12-output-2.png" width="1590" height="302"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-12-output-3.png" width="830" height="302"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-12-output-4.png" width="968" height="350"></p>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kathi/miniconda3/envs/final_project_aml/lib/python3.10/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.
  warnings.warn(
/home/kathi/miniconda3/envs/final_project_aml/lib/python3.10/site-packages/captum/attr/_core/deep_lift.py:336: UserWarning: Setting forward, backward hooks and attributes on non-linear
               activations. The hooks and attributes will be removed
            after the attribution is finished
  warnings.warn(
/tmp/ipykernel_427167/809386396.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  plot_df = plot_df.append(tf_df)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-12-output-6.png" width="1590" height="302"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-12-output-7.png" width="830" height="302"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-12-output-8.png" width="968" height="350"></p>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kathi/miniconda3/envs/final_project_aml/lib/python3.10/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.
  warnings.warn(
/home/kathi/miniconda3/envs/final_project_aml/lib/python3.10/site-packages/captum/attr/_core/deep_lift.py:336: UserWarning: Setting forward, backward hooks and attributes on non-linear
               activations. The hooks and attributes will be removed
            after the attribution is finished
  warnings.warn(
/tmp/ipykernel_427167/809386396.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  plot_df = plot_df.append(tf_df)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-12-output-10.png" width="1590" height="302"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-12-output-11.png" width="830" height="302"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-12-output-12.png" width="968" height="350"></p>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kathi/miniconda3/envs/final_project_aml/lib/python3.10/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.
  warnings.warn(
/home/kathi/miniconda3/envs/final_project_aml/lib/python3.10/site-packages/captum/attr/_core/deep_lift.py:336: UserWarning: Setting forward, backward hooks and attributes on non-linear
               activations. The hooks and attributes will be removed
            after the attribution is finished
  warnings.warn(
/tmp/ipykernel_427167/809386396.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  plot_df = plot_df.append(tf_df)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-12-output-14.png" width="1590" height="302"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-12-output-15.png" width="830" height="302"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-12-output-16.png" width="959" height="350"></p>
</div>
</div>
</section>
<section id="fbx15-enhancer-supplementary-fig.2" class="level3" data-number="2.0.3">
<h3 data-number="2.0.3" class="anchored" data-anchor-id="fbx15-enhancer-supplementary-fig.2"><span class="header-section-number">2.0.3</span> Fbx15 enhancer (Supplementary Fig.2)</h3>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>contr, dist_start, pred <span class="op">=</span> get_contr_region(<span class="st">"chr18"</span>, start<span class="op">=</span><span class="dv">84934461</span>, end<span class="op">=</span><span class="dv">84934521</span>, dataset<span class="op">=</span>train_dataset, output_dir<span class="op">=</span>OUTPUT_DIR, dl<span class="op">=</span>dl, tf_list<span class="op">=</span>TF_LIST, device<span class="op">=</span>device, model<span class="op">=</span>model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kathi/miniconda3/envs/final_project_aml/lib/python3.10/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.
  warnings.warn(
/home/kathi/miniconda3/envs/final_project_aml/lib/python3.10/site-packages/captum/attr/_core/deep_lift.py:336: UserWarning: Setting forward, backward hooks and attributes on non-linear
               activations. The hooks and attributes will be removed
            after the attribution is finished
  warnings.warn(
/tmp/ipykernel_427167/809386396.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  plot_df = plot_df.append(tf_df)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-13-output-2.png" width="1590" height="302"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-13-output-3.png" width="830" height="302"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-13-output-4.png" width="968" height="350"></p>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kathi/miniconda3/envs/final_project_aml/lib/python3.10/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.
  warnings.warn(
/home/kathi/miniconda3/envs/final_project_aml/lib/python3.10/site-packages/captum/attr/_core/deep_lift.py:336: UserWarning: Setting forward, backward hooks and attributes on non-linear
               activations. The hooks and attributes will be removed
            after the attribution is finished
  warnings.warn(
/tmp/ipykernel_427167/809386396.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  plot_df = plot_df.append(tf_df)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-13-output-6.png" width="1590" height="302"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-13-output-7.png" width="819" height="302"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-13-output-8.png" width="968" height="350"></p>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kathi/miniconda3/envs/final_project_aml/lib/python3.10/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.
  warnings.warn(
/home/kathi/miniconda3/envs/final_project_aml/lib/python3.10/site-packages/captum/attr/_core/deep_lift.py:336: UserWarning: Setting forward, backward hooks and attributes on non-linear
               activations. The hooks and attributes will be removed
            after the attribution is finished
  warnings.warn(
/tmp/ipykernel_427167/809386396.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  plot_df = plot_df.append(tf_df)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-13-output-10.png" width="1590" height="302"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-13-output-11.png" width="830" height="302"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-13-output-12.png" width="959" height="351"></p>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/kathi/miniconda3/envs/final_project_aml/lib/python3.10/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.
  warnings.warn(
/home/kathi/miniconda3/envs/final_project_aml/lib/python3.10/site-packages/captum/attr/_core/deep_lift.py:336: UserWarning: Setting forward, backward hooks and attributes on non-linear
               activations. The hooks and attributes will be removed
            after the attribution is finished
  warnings.warn(
/tmp/ipykernel_427167/809386396.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  plot_df = plot_df.append(tf_df)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-13-output-14.png" width="1590" height="302"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-13-output-15.png" width="830" height="302"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="05_interpretability_files/figure-html/cell-13-output-16.png" width="959" height="350"></p>
</div>
</div>
</section>
</section>
<section id="input-x-gradient" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Input x Gradient</h1>
<p>For the same exemplary regions from the paper.</p>
<pre class="#{python}"><code>grad, grad_in = input_gradient("chr4", start=55475545, end=55475604, dataset=tune_dataset,output_dir=OUTPUT_DIR, 
model=model, tf_list=TF_LIST, device=device)</code></pre>
<section id="klf4-e2-enhancer-supplementary-fig.2-1" class="level3" data-number="3.0.1">
<h3 data-number="3.0.1" class="anchored" data-anchor-id="klf4-e2-enhancer-supplementary-fig.2-1"><span class="header-section-number">3.0.1</span> Klf4 E2 enhancer (Supplementary Fig.2)</h3>
<pre class="#{python}"><code>
grad, grad_in = input_gradient("chr4", start=55475545, end=55475604, dataset=tune_dataset,output_dir=OUTPUT_DIR, 
 model=model, tf_list=TF_LIST, device=device)
</code></pre>
</section>
<section id="nanog-enhancer-supplementary-fig.2-1" class="level3" data-number="3.0.2">
<h3 data-number="3.0.2" class="anchored" data-anchor-id="nanog-enhancer-supplementary-fig.2-1"><span class="header-section-number">3.0.2</span> Nanog enhancer (Supplementary Fig.2)</h3>
<pre class="#{python}"><code>
grad, grad_in = input_gradient("chr6", start=122707394, end=122707454, dataset=train_dataset, output_dir=OUTPUT_DIR, 
model=model, tf_list=TF_LIST, device=device)
</code></pre>
</section>
<section id="fbx15-enhancer-supplementary-fig.2-1" class="level3" data-number="3.0.3">
<h3 data-number="3.0.3" class="anchored" data-anchor-id="fbx15-enhancer-supplementary-fig.2-1"><span class="header-section-number">3.0.3</span> Fbx15 enhancer (Supplementary Fig.2)</h3>
<pre class="#{python}"><code>

grad, grad_in = input_gradient("chr17", start=35504453, end=35504603, dataset=train_dataset, output_dir=OUTPUT_DIR, 
model=model, tf_list=TF_LIST, device=device)

</code></pre>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>